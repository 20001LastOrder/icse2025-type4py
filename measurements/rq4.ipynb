{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_result_classification(df, type_check_failed=False, typecheck=True, sample_weight=1, beta=1):\n",
    "    # remove special cases for finetuned models: the program is longer than context size\n",
    "    if typecheck:\n",
    "        df = df[df['type_check_failed'] == type_check_failed]\n",
    "    df = df.copy()\n",
    "    df[\"gt_label\"] = df[\"gt_error_loc\"] > 0\n",
    "    df[\"pred_label\"] = (df[\"loc_pred\"] == df[\"gt_error_loc\"]) & (df[\"gt_label\"])\n",
    "    df[\"sample_weight\"] = sample_weight * df[\"gt_label\"] + (~df[\"gt_label\"])\n",
    "    \n",
    "\n",
    "    tp = (df[\"loc_pred\"] == df[\"gt_error_loc\"]) & (df[\"gt_label\"])\n",
    "    tp = (tp * df[\"sample_weight\"]).sum()\n",
    "    tn = (df[\"loc_pred\"] == 0) & (~df[\"gt_label\"])\n",
    "    tn = (tn * df[\"sample_weight\"]).sum()\n",
    "    pp = df[\"loc_pred\"] > 0\n",
    "    pp = (pp * df[\"sample_weight\"]).sum()\n",
    "    fp = pp - tp\n",
    "    fn = (df[\"loc_pred\"] == 0) & (df[\"gt_label\"])\n",
    "    fn = (fn * df[\"sample_weight\"]).sum()\n",
    "\n",
    "    print(f\"tp: {tp}, tn: {tn}, fp: {fp}, fn: {fn}\")\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    # mcc = (tp * tn - fp * fn) / ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n",
    "\n",
    "    fb = (1 + beta ** 2) * precision * recall / (beta ** 2 * precision + recall)\n",
    "\n",
    "\n",
    "    return precision, recall, fb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_sample_ids(df, end_idx=1291):\n",
    "    if \"sample_id\" not in df.columns:\n",
    "        return df\n",
    "    df_bugs = df[df[\"gt_error_loc\"] > 0]\n",
    "    df_no_bugs = df[df[\"gt_error_loc\"] == 0]\n",
    "\n",
    "    records = df_no_bugs.to_dict(\"records\")\n",
    "    for i, record in enumerate(records):\n",
    "        record[\"sample_id\"] = i + end_idx\n",
    "\n",
    "    return pd.concat([df_bugs, pd.DataFrame(records)])\n",
    "\n",
    "def precess_df(folder, filename, leak_max_idx=None, perform_test_leak=True, reset_sample_id=False):\n",
    "    type_files = glob.glob(f\"{folder}/typechecking/*.csv\")\n",
    "\n",
    "    type_check_df = pd.concat([pd.read_csv(file) for file in type_files])\n",
    "    type_check_df = type_check_df.reset_index()\n",
    "\n",
    "    if perform_test_leak:\n",
    "        test_leak = pd.read_csv(f\"{folder}/test_leak.csv\", index_col=0)\n",
    "        if leak_max_idx:\n",
    "            test_leak = test_leak.iloc[:leak_max_idx]\n",
    "\n",
    "    ground_truth_df = pd.read_csv(f\"{folder}/ground_truth.csv\")\n",
    "\n",
    "    df = pd.read_csv(f\"{folder}/{filename}\")\n",
    "    \n",
    "    if reset_sample_id:\n",
    "        df = reset_sample_ids(df, end_idx=leak_max_idx)\n",
    "\n",
    "    if \"sample_id\" in df.columns:\n",
    "        df = df.set_index(\"sample_id\")\n",
    "    elif \"sample_ids\" in df.columns:\n",
    "        df = df.set_index(\"sample_ids\")\n",
    "\n",
    "    df = df.drop(columns=[\"gt_error_loc\"])\n",
    "    df = df.join(ground_truth_df)\n",
    "\n",
    "    if perform_test_leak:\n",
    "        df = df.join(test_leak)\n",
    "        df = df.fillna(False)\n",
    "        df = df[df[\"leaked\"] == False]\n",
    "    df = df.join(type_check_df)\n",
    "    df.fillna(False, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_performance(df, settings = (\"codebert\", \"graphcodebert\", \"unixcoder\", \"ggnn\", \"great\", \"transformer\")):\n",
    "    records = df.to_dict(\"records\")\n",
    "    settings_map = set(settings)\n",
    "    base_map = dict()\n",
    "    for record in records:\n",
    "        if record[\"setup\"] in settings_map:\n",
    "            base_map[record[\"setup\"]] = record\n",
    "\n",
    "    results = []\n",
    "    for record in records:\n",
    "        if record[\"setup\"] in settings_map:\n",
    "            continue\n",
    "        name = record[\"setup\"].split(\" \")[0]\n",
    "        if name not in base_map:\n",
    "            print(f\"Warning: missing base performance for {name}\")\n",
    "            continue\n",
    "\n",
    "        base_performance = base_map[name]\n",
    "        result = {\"setup\": record[\"setup\"]}\n",
    "        for key in record.keys():\n",
    "            if key == \"setup\":\n",
    "                continue\n",
    "            result[key] = (record[key] - base_performance[key])\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_performance_change(df, settings = (\"codebert\", \"graphcodebert\", \"unixcoder\", \"ggnn\", \"great\", \"transformer\")):\n",
    "    records = df.to_dict(\"records\")\n",
    "    settings_map = set(settings)\n",
    "    base_map = dict()\n",
    "    for record in records:\n",
    "        if record[\"setup\"] in settings_map:\n",
    "            base_map[record[\"setup\"]] = record\n",
    "\n",
    "    results = []\n",
    "    for record in records:\n",
    "        if record[\"setup\"] in settings_map:\n",
    "            continue\n",
    "        name = record[\"setup\"].split(\" \")[0]\n",
    "        if name not in base_map:\n",
    "            print(f\"Warning: missing base performance for {name}\")\n",
    "            continue\n",
    "\n",
    "        base_performance = base_map[name]\n",
    "        result = {\"setup\": record[\"setup\"]}\n",
    "        for key in record.keys():\n",
    "            if key == \"setup\":\n",
    "                continue\n",
    "            result[key] =  f\"{'{:.2f}'.format(base_performance[key])} -> {'{:.2f}'.format(record[key])}\"\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def reset_sample_ids(df, end_idx=1291):\n",
    "    if \"sample_id\" not in df.columns:\n",
    "        return df\n",
    "    df_bugs = df[df[\"gt_error_loc\"] > 0]\n",
    "    df_no_bugs = df[df[\"gt_error_loc\"] == 0]\n",
    "\n",
    "    records = df_no_bugs.to_dict(\"records\")\n",
    "    for i, record in enumerate(records):\n",
    "        record[\"sample_id\"] = i + end_idx\n",
    "\n",
    "    return pd.concat([df_bugs, pd.DataFrame(records)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "real1_folder = \"results/real_1\"\n",
    "real2_folder = \"results/real_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_map = {\n",
    "    \"codebert\": \"codebert.csv\",\n",
    "    \"codebert typecheck oversample\": \"codebert_typecheck_oversample.csv\",\n",
    "    \"graphcodebert\": \"graphcodebert.csv\",\n",
    "    \"graphcodebert typecheck oversample\": \"graphcodebert_typecheck_oversample.csv\",\n",
    "    \"unixcoder\": \"unixcoder.csv\",\n",
    "    \"unixcoder typecheck oversample\": \"unixcoder_typecheck_oversample.csv\",\n",
    "    \"ggnn\": \"ggnn.csv\",\n",
    "    \"ggnn typecheck oversample\": \"ggnn_typecheck_oversample.csv\",\n",
    "    \"great\": \"great.csv\",\n",
    "    \"great typecheck oversample\": \"great_typecheck_oversample.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 615, tn: 32122, fp: 1666, fn: 1316\n",
      "tp: 608, tn: 32021, fp: 1778, fn: 1312\n",
      "tp: 626, tn: 32283, fp: 1487, fn: 1323\n",
      "tp: 679, tn: 32130, fp: 1642, fn: 1268\n",
      "tp: 664, tn: 32272, fp: 1500, fn: 1283\n",
      "tp: 709, tn: 32087, fp: 1695, fn: 1228\n",
      "tp: 288, tn: 30505, fp: 2644, fn: 1420\n",
      "tp: 292, tn: 30349, fp: 2807, fn: 1409\n",
      "tp: 403, tn: 29296, fp: 3993, fn: 1165\n",
      "tp: 431, tn: 29448, fp: 3824, fn: 1154\n"
     ]
    }
   ],
   "source": [
    "beta = 1.5\n",
    "results = []\n",
    "for key, filename in setting_map.items():\n",
    "    df_real1 = precess_df(real1_folder, filename, leak_max_idx=1292, reset_sample_id=True)  # 1292 faulty programs, correct programs are already filtered\n",
    "    df_real2 = precess_df(real2_folder, filename)\n",
    "    df =  pd.concat([df_real1, df_real2])\n",
    "    df = df.reset_index()\n",
    "    metrics = measure_result_classification(df, typecheck=True, beta=beta)\n",
    "    \n",
    "    results.append({\n",
    "        \"setup\": key,\n",
    "        \"precision\": metrics[0] * 100,\n",
    "        \"recall\": metrics[1] * 100,\n",
    "        \"fb\": metrics[2] * 100,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "                              setup &       precision &          recall &              fb \\\\\n",
      "\\midrule\n",
      "      codebert typecheck oversample &  26.96 -> 25.48 &  31.85 -> 31.67 &  30.17 -> 29.47 \\\\\n",
      " graphcodebert typecheck oversample &  29.63 -> 29.25 &  32.12 -> 34.87 &  31.31 -> 32.93 \\\\\n",
      "     unixcoder typecheck oversample &  30.68 -> 29.49 &  34.10 -> 36.60 &  32.97 -> 34.08 \\\\\n",
      "          ggnn typecheck oversample &    9.82 -> 9.42 &  16.86 -> 17.17 &  13.82 -> 13.70 \\\\\n",
      "         great typecheck oversample &   9.17 -> 10.13 &  25.70 -> 27.19 &  16.53 -> 17.91 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(relative_performance_change(result_df).round(2).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>codebert typecheck oversample</td>\n",
       "      <td>-1.479881</td>\n",
       "      <td>-0.182116</td>\n",
       "      <td>-0.700247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>graphcodebert typecheck oversample</td>\n",
       "      <td>-0.371492</td>\n",
       "      <td>2.755130</td>\n",
       "      <td>1.619537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unixcoder typecheck oversample</td>\n",
       "      <td>-1.191406</td>\n",
       "      <td>2.499245</td>\n",
       "      <td>1.102203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ggnn typecheck oversample</td>\n",
       "      <td>-0.400252</td>\n",
       "      <td>0.304546</td>\n",
       "      <td>-0.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great typecheck oversample</td>\n",
       "      <td>0.961835</td>\n",
       "      <td>1.490898</td>\n",
       "      <td>1.380642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                setup  precision    recall        fb\n",
       "0       codebert typecheck oversample  -1.479881 -0.182116 -0.700247\n",
       "1  graphcodebert typecheck oversample  -0.371492  2.755130  1.619537\n",
       "2      unixcoder typecheck oversample  -1.191406  2.499245  1.102203\n",
       "3           ggnn typecheck oversample  -0.400252  0.304546 -0.114000\n",
       "4          great typecheck oversample   0.961835  1.490898  1.380642"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_performance(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_folder = \"results/synthetic_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_map = {\n",
    "    \"codebert\": \"codebert.csv\",\n",
    "    \"codebert typecheck oversample\": \"codebert_typecheck_oversample.csv\",\n",
    "    \"graphcodebert\": \"graphcodebert.csv\",\n",
    "    \"graphcodebert typecheck oversample\": \"graphcodebert_typecheck_oversample.csv\",\n",
    "    \"unixcoder\": \"unixcoder.csv\",\n",
    "    \"unixcoder typecheck oversample\": \"unixcoder_typecheck_oversample.csv\",\n",
    "    \"ggnn\": \"ggnn.csv\",\n",
    "    \"ggnn typecheck oversample\": \"ggnn_typecheck_oversample.csv\",\n",
    "    \"great\": \"great.csv\",\n",
    "    \"great typecheck oversample\": \"great_typecheck_oversample.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 344203, tn: 464562, fp: 30303, fn: 35011\n",
      "tp: 345406, tn: 462642, fp: 32579, fn: 33452\n",
      "tp: 347608, tn: 466034, fp: 27652, fn: 32785\n",
      "tp: 348307, tn: 464249, fp: 29779, fn: 31744\n",
      "tp: 352936, tn: 465928, fp: 27788, fn: 27427\n",
      "tp: 354013, tn: 463969, fp: 29860, fn: 26237\n",
      "tp: 278803, tn: 442262, fp: 56601, fn: 81826\n",
      "tp: 281328, tn: 441134, fp: 58529, fn: 78501\n",
      "tp: 312835, tn: 430804, fp: 71304, fn: 44549\n",
      "tp: 314259, tn: 433207, fp: 68051, fn: 43975\n"
     ]
    }
   ],
   "source": [
    "beta = 1.5\n",
    "results = []\n",
    "for key, filename in setting_map.items():\n",
    "    df = precess_df(synthetic_folder, filename, perform_test_leak=False)\n",
    "\n",
    "    metrics = measure_result_classification(df, typecheck=True, beta=beta)\n",
    "    \n",
    "    results.append({\n",
    "        \"setup\": key,\n",
    "        \"precision\": metrics[0] * 100,\n",
    "        \"recall\": metrics[1] * 100,\n",
    "        \"fb\": metrics[2] * 100,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>codebert typecheck oversample</td>\n",
       "      <td>91.91 -&gt; 91.38</td>\n",
       "      <td>90.77 -&gt; 91.17</td>\n",
       "      <td>91.12 -&gt; 91.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>graphcodebert typecheck oversample</td>\n",
       "      <td>92.63 -&gt; 92.12</td>\n",
       "      <td>91.38 -&gt; 91.65</td>\n",
       "      <td>91.76 -&gt; 91.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unixcoder typecheck oversample</td>\n",
       "      <td>92.70 -&gt; 92.22</td>\n",
       "      <td>92.79 -&gt; 93.10</td>\n",
       "      <td>92.76 -&gt; 92.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ggnn typecheck oversample</td>\n",
       "      <td>83.12 -&gt; 82.78</td>\n",
       "      <td>77.31 -&gt; 78.18</td>\n",
       "      <td>79.01 -&gt; 79.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great typecheck oversample</td>\n",
       "      <td>81.44 -&gt; 82.20</td>\n",
       "      <td>87.53 -&gt; 87.72</td>\n",
       "      <td>85.56 -&gt; 85.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                setup       precision          recall  \\\n",
       "0       codebert typecheck oversample  91.91 -> 91.38  90.77 -> 91.17   \n",
       "1  graphcodebert typecheck oversample  92.63 -> 92.12  91.38 -> 91.65   \n",
       "2      unixcoder typecheck oversample  92.70 -> 92.22  92.79 -> 93.10   \n",
       "3           ggnn typecheck oversample  83.12 -> 82.78  77.31 -> 78.18   \n",
       "4          great typecheck oversample  81.44 -> 82.20  87.53 -> 87.72   \n",
       "\n",
       "               fb  \n",
       "0  91.12 -> 91.23  \n",
       "1  91.76 -> 91.79  \n",
       "2  92.76 -> 92.83  \n",
       "3  79.01 -> 79.54  \n",
       "4  85.56 -> 85.95  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_performance_change(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setup</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>codebert typecheck oversample</td>\n",
       "      <td>-0.527666</td>\n",
       "      <td>0.402824</td>\n",
       "      <td>0.119445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>graphcodebert typecheck oversample</td>\n",
       "      <td>-0.507493</td>\n",
       "      <td>0.266155</td>\n",
       "      <td>0.031192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unixcoder typecheck oversample</td>\n",
       "      <td>-0.479889</td>\n",
       "      <td>0.310809</td>\n",
       "      <td>0.065757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ggnn typecheck oversample</td>\n",
       "      <td>-0.346185</td>\n",
       "      <td>0.873604</td>\n",
       "      <td>0.531557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great typecheck oversample</td>\n",
       "      <td>0.762078</td>\n",
       "      <td>0.189808</td>\n",
       "      <td>0.383440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                setup  precision    recall        fb\n",
       "0       codebert typecheck oversample  -0.527666  0.402824  0.119445\n",
       "1  graphcodebert typecheck oversample  -0.507493  0.266155  0.031192\n",
       "2      unixcoder typecheck oversample  -0.479889  0.310809  0.065757\n",
       "3           ggnn typecheck oversample  -0.346185  0.873604  0.531557\n",
       "4          great typecheck oversample   0.762078  0.189808  0.383440"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_performance(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "                              setup &       precision &          recall &              fb \\\\\n",
      "\\midrule\n",
      "      codebert typecheck oversample &  91.91 -> 91.38 &  90.77 -> 91.17 &  91.12 -> 91.23 \\\\\n",
      " graphcodebert typecheck oversample &  92.63 -> 92.12 &  91.38 -> 91.65 &  91.76 -> 91.79 \\\\\n",
      "     unixcoder typecheck oversample &  92.70 -> 92.22 &  92.79 -> 93.10 &  92.76 -> 92.83 \\\\\n",
      "          ggnn typecheck oversample &  83.12 -> 82.78 &  77.31 -> 78.18 &  79.01 -> 79.54 \\\\\n",
      "         great typecheck oversample &  81.44 -> 82.20 &  87.53 -> 87.72 &  85.56 -> 85.95 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(relative_performance_change(result_df).round(2).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustgnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
